## ReplicationController

# ***Сейчас уже заменён ReplicaSet'ом, да и тот в свою очередь запускается Deployment'ом, но всё же***

это ресурс кубера, обеспечивающий поддержание постойнной работы его подов, отслеживает кол-во реплик и поддерживает его

<details> <summary>rc-kuber.yaml</summary>

```
apiVersion: v1
kind: ReplicationController
metadata:
  name: kuber-rc
spec:
  replicas: 3
  selector:               # Селектор меток, определяет какие поды находятся в области действия контроллера
    app: http-server      # должен совпадать с меткой в template: labels:
  template:               # Шаблон, будет создавать 3 реплики, основываясь на этом шаблоне
    metadata:
      name: kuber-app
      labels:             # должен совпадать с меткой в selector:
        app: http-server  # иначе ReplicationController не может управлять подами и не будет поддерживать необходимое кол-во реплик
    spec:
      containers:
      - name: http-server-image
        image: bokovets/kuber
        ports:
        - containerPort: 8000
```
</details>

selector: (app: http-server) ReplicationController и labels: (app: http-server) подов должны совпадать,чтобы он их контролил

![image](https://github.com/user-attachments/assets/58b308ad-8460-4df4-9ff7-5b809e338333)

Теперь при удалении пода ReplicationController будет поднимать новый, а если попытаться поднять

<details> <summary>kuber-pod.yml</summary>

```
apiVersion: v1
kind: Pod
metadata:
  name: kuber-app-manual
  labels:
    app: http-server
spec:
  containers:
  - name: kuber-app-image
    image: bokovets/kuber
    ports:
    - containerPort: 8000
```
</details>

то он его зарегистрирует к себе, т.к совпадают labels: app: http-server, но не создаст, т.к реплик и так уже 3

если же поменять label(или его значение) у пода, к примеру, на env (или 'test-server'), то ReplicationController больше не будет его контролировать, а создаст новый

если же поменять label и selector у ReplicationController, то он создаст новые 3 пода, старые останутся,но он уже не будет их контролить

если хотим изменить image подов, то придется удалять их вручную, а потом ReplicationController уже пересоздаст новые с измененным image

при удалении ReplicationController удалятся и созданные контролером поды

## ReplicaSet

<details> <summary>rs-kuber.yaml</summary>

```
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: kuber-rs-1
  labels:            # тут можно хоть что писать потому что...
    app: kuber-rs    # ...это относится к ReplicaSet, а не к подам
spec:
  replicas: 3
  selector:
    matchLabels:     # здесь уже должно совпадать...
      env: dev       # ...c labels: env:dev
  template:
    metadata:
      labels:        # должно совпадать с...
        env: dev     # ...matchLabels: env:dev
    spec:
      containers:
      - name: kuber-app
        image: bokovets/kuber
```
</details>

По большому счёту, отличается от ReplicationController тем,что позволяет более гибко настраивать правила для label

<details> <summary>rs-kuber-matchExpressions.yaml</summary>

```
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: kuber-rs-2
spec:
  replicas: 3
  selector:
    matchExpressions:    # поддерживается 4 вида операторa: In, notIn, Exists, doesntExists
      - key: app         # ключ app...
        operator: In     # ...должен быть...
        values:
          - kuber        # ...либо kuber...
          - http-server  # ...либо http-server
      - key: env         # а здесь ключ env...
        operator: Exists # ...должен, впринципе, существовать
  template:
    metadata:
      labels:
        app: kuber       # соответствует, т.к в matchExpressions: key: app должен быть либо kuber, либо http-server
        env: dev         # так же соответствует, т.к впринципе env существует, не важно dev или huev
    spec:
      containers:
      - name: kuber-app
        image: bokovets/kuber
```
</details>

