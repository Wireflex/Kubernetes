# LivenessProbe
используется для проверки, когда перезапустить контейнер. Например, liveness проба должна поймать блокировку, когда приложение запущено, но не может ничего сделать. В этом случае перезапуск приложения может помочь сделать приложение более доступным, несмотря на баги.

По сути проверяет контейнер - жив он или нет, если не проходит проверку(сдох,ошибка итд) - перезапускает. Все пробы выполняет kubelet-agent на каждой НОДЕ

3 типа проверок:
- httpGet
- TCP
- exec

## Exec-LivenessProbe
выполняет произвольную команду внутри контейнера и проверяет код состояния на выходе из команды ( 0 успех, всё остальное нет )

<details> <summary>kuber-deploy-livenessProbe-exec.yaml</summary>

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ubuntu
  labels:
    app: ubuntu
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ubuntu
  template:
    metadata:
      labels:
        app: ubuntu
    spec:
      containers:
      - name: ubuntu
        image: ubuntu
        args:
        - /bin/sh
        - -c
        - touch /tmp/healthy; sleep 30; rm -rf /tmp/healthy; sleep 600     # создаёт файл, спит 30 сек и удаляет,спит 10 мин
        livenessProbe:
          exec:                       # указание типа проверки
            command:
            - cat                     # проверка командой cat...
            - /tmp/healthy            # ...существует ли этот файл
          initialDelaySeconds: 5      # Количество секунд от старта контейнера до пробы. По дефолту 0 секунд. Минимум 0.
          periodSeconds: 5            # Длительность времени между двумя последовательными проведениям проб. По дефолту до 10 секунд. Минимум 1.
          timeoutSeconds: 1           # Кол-во секунд ожидания пробы(если что-то идёт не так - она падает по таймауту и считается failure) По дефолту 1 секунда. Минимум 1.
          successThreshold: 1         # Миннимальное кол-во последовательных проверок чтобы проба считалась успешной после неудачной. По дефолту до 1. Должно быть 1 для liveness and startup Probes. Минимум 1.
          failureThreshold: 3         # После задонного кол-ва (3) контейнер считается умершим. Дефолт до 3. Минимум 1.
```
</details>

через 30 секунд файл healthy помер и проба перезапустила контейнер

![image](https://github.com/user-attachments/assets/8aaa9608-2bde-47d6-b6f4-0a7bc9bfe5ce)

и так до бесконечности

![image](https://github.com/user-attachments/assets/0f28d900-3268-4d3b-99d2-b98e1687359c)

## TCP-LivenessProbe
пытается открыть TCP подключение к указанному порту контейнера, успех = успех, иначе перезапуск

<details> <summary>kuber-deploy-livenessProbe-tcp.yaml</summary>

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kuber-tcp
  labels:
    app: kuber
spec:
  replicas: 1
  selector:
    matchLabels:
      app: http-server-tcp
  template:
    metadata:
      labels:
        app: http-server-tcp
    spec:
      containers:
      - name: kuber-app
        image: bakavets/kuber:v1.0
        ports:
        - containerPort: 8000
        livenessProbe:
          tcpSocket:                # указание типа проверки
            port: 8001              # пытается открыть TCP-подключение к указанному порту (он тут неправильный, должен быть 8000)
          initialDelaySeconds: 15   # Дефолт 0. Минимум 0
          periodSeconds: 10         # Дефолт до 10. Минимум 1
          timeoutSeconds: 1         # Дефолт до 1. Минимум 1
          successThreshold: 1       # Дефолт до 1. Должно быть 1 для liveness and startup Probes. Минимум 1
          failureThreshold: 3       # Дефолт до 3. Минимум 1
---
apiVersion: v1
kind: Service
metadata:
  name: kuber-service-tcp
spec:
  selector:
    app: http-server-tcp
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
      nodePort: 30002
  type: NodePort
```
</details>

![image](https://github.com/user-attachments/assets/e2420f0d-662a-4330-9461-3c365d10d4f3)

8001 ничего не слушает, поэтому после 3 попыток - перезапуск, и опять же, так до бесконечности

## httpGet-LivenessProbe
выполняет запрос http GET на ip:port и путь контейнера, который указан, коды 200ые=успех, 400ые и 500ые ошибки - failure и перезапуск

<details> <summary>kuber-deploy-livenessProbe-http.yaml</summary>

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kuber-http
  labels:
    app: kuber
spec:
  replicas: 1
  selector:
    matchLabels:
      app: http-server-http
  template:
    metadata:
      labels:
        app: http-server-http
    spec:
      containers:
      - name: kuber-app
        image: bakavets/kuber:v1.0-unhealthy
        ports:
        - containerPort: 8000
        livenessProbe:
          httpGet:
            path: /healthcheck
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: kuber-service-http
spec:
  selector:
    app: http-server-http
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
      nodePort: 30003
  type: NodePort
```
</details>

новый image: bakavets/kuber:v1.0-unhealthy 

![image](https://github.com/user-attachments/assets/ab58b0f5-41d9-478a-ac6b-ebc5c233ce4b)

где после 5 запросов на /healthcheck выдаётся 500 ошибка, а на корневой / статус 200

![Снимок экрана 2024-08-25 005141](https://github.com/user-attachments/assets/9e3ff6db-8be4-4533-be7b-c461ec9a02c7)

проба сама начинает делать запросы, проверяя состояние контейнера,тем самым провоцируя ERROR, и после 5 запросов(проверок) выдаётся ошибка и далее проба рестартит контейнер

![image](https://github.com/user-attachments/assets/d0e49cdc-333a-4d33-965b-bcf3dc9c8aaa)

# ReadinessProbe
нужна для понимания когда регистрировать под к сервису,чтобы направлять на него трафик(если ошибка и не проходит healthcheck,к примеру, нет смысла отправлять трафик на под)

Все механизмы ( httpGet, TCP, exec ) так же используются в ReadinessProbe

<details> <summary>kuber-deploy-readinessProbe-http.yaml</summary>

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kuber-http-readinessprobe
  labels:
    app: kuber
spec:
  replicas: 1
  selector:
    matchLabels:
      app: http-server-default
  template:
    metadata:
      labels:
        app: http-server-default
    spec:
      containers:
      - name: kuber-app
        image: bakavets/kuber:v1.0-unhealthy
        ports:
        - containerPort: 8000
        readinessProbe:
          httpGet:
            path: /healthcheck
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```
</details>
и еще поднимем
<details> <summary>kuber-deploy.yaml</summary>

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kuber-default
  labels:
    app: kuber
spec:
  replicas: 1
  selector:
    matchLabels:
      app: http-server-default
  template:
    metadata:
      labels:
        app: http-server-default
    spec:
      containers:
      - name: kuber-app
        image: bakavets/kuber:v1.0
        ports:
        - containerPort: 8000
---
apiVersion: v1
kind: Service
metadata:
  name: kuber-default-service
spec:
  selector:
    app: http-server-default
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
      nodePort: 30001
```
</details>

для того,чтобы к сервису в kuber-deploy были присвоены все поды от kuber-deploy-readinessProbe, то есть в итоге сервис в kuber-deploy будет обслуживать 2 deployment'а : и kuber-default(kuber-deploy.yaml) и kuber-http-readinessprobe(kuber-deploy-readinessProbe-http.yaml)

![image](https://github.com/user-attachments/assets/0fad0eeb-4a33-4358-8d17-cdf6765951d3)

трафик начинает поступать на новый deployment в kuber-deploy-readinessProbe, но так как после 5 проверок, как и раньше, выдаётся ошибка - под умирает, НО НЕ ПЕРЕЗАПУСКАЕТСЯ как в LivenessProbe, т.к смысл ReadinessProbes понимать отправлять на ПОДУ трафик или нет

есть смысл юзать их вместе, чтобы LivenessProbe перезапускала, а ReadinessProbes в итоге подцепила ПОД к себе только тогда,когда не будет выдаваться ошибка от проверок, соответственно и будет смысл уже отправлять на ПОДУ трафик

<details> <summary>kuber-deploy-readiness_livenesssProbe-http.yaml</summary>

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kuber-http-readiness_livenessprobe
  labels:
    app: kuber
spec:
  replicas: 1
  selector:
    matchLabels:
      app: http-server-default
  template:
    metadata:
      labels:
        app: http-server-default
    spec:
      containers:
      - name: kuber-app
        image: bakavets/kuber:v1.0-unhealthy
        ports:
        - containerPort: 8000
        readinessProbe:
          httpGet:
            path: /healthcheck
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /healthcheck
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
```
</details>
